{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6671c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767a114",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd494351",
   "metadata": {},
   "source": [
    "This file gets the data from the MIMIC-III database and formats it to be used by our Pretraining method and Fine Tuning method.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2dfb73",
   "metadata": {},
   "source": [
    "**Single Visit Task**: pyhealth task that finds all the patients with only one visit and makes an object for that visit of the form:\n",
    "```\n",
    "{\n",
    "    \"visit_id\": id of given visit,\n",
    "    \"patient_id\" id of patient,\n",
    "    \"conditions\": list of ICD9 codes indicating the conditions recorded in the visit,\n",
    "    \"drugs\": list of ATC codes indicating the drugs perscribed in the visit\n",
    "}\n",
    "```\n",
    "reference:\n",
    "<br/>\n",
    "1. https://pyhealth.readthedocs.io/en/latest/_modules/pyhealth/tasks/drug_recommendation.html#drug_recommendation_mimic3_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8264570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_visit_fn(patient):\n",
    "    samples = []\n",
    "    for i in range(len(patient)):\n",
    "        visit: Visit = patient[i]\n",
    "        conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        drugs = visit.get_code_list(table=\"PRESCRIPTIONS\")\n",
    "        \n",
    "        drugs = [drug[:4] for drug in drugs]\n",
    "        \n",
    "        if len(conditions) * len(drugs) == 0:\n",
    "            continue\n",
    "        samples.append(\n",
    "            {\n",
    "                \"visit_id\": visit.visit_id,\n",
    "                \"patient_id\": patient.patient_id,\n",
    "                \"conditions\": conditions,\n",
    "                \"drugs\": drugs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if len(samples) != 1:\n",
    "        return []\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b915db",
   "metadata": {},
   "source": [
    "**Multi Visit Task**: pyhealth task that finds all the patients with multiple visits and makes an object for that visit of the form:\n",
    "```\n",
    "{\n",
    "    \"visit_id\": id of given visit,\n",
    "    \"patient_id\" id of patient,\n",
    "    \"conditions\": list of ICD9 codes indicating the conditions recorded in the visit,\n",
    "    \"drugs\": list of ATC codes indicating the drugs perscribed in the visit\n",
    "}\n",
    "```\n",
    "reference:\n",
    "<br/>\n",
    "1. https://pyhealth.readthedocs.io/en/latest/_modules/pyhealth/tasks/drug_recommendation.html#drug_recommendation_mimic3_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af32c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_visit_fn(patient):\n",
    "    samples = []\n",
    "    for i in range(len(patient)):\n",
    "        visit: Visit = patient[i]\n",
    "        conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        drugs = visit.get_code_list(table=\"PRESCRIPTIONS\")\n",
    "        # ATC 3 level\n",
    "        drugs = [drug[:4] for drug in drugs]\n",
    "        # exclude: visits without condition or drug code\n",
    "        if len(conditions) * len(drugs) == 0:\n",
    "            continue\n",
    "        samples.append(\n",
    "            {\n",
    "                \"visit_id\": visit.visit_id,\n",
    "                \"patient_id\": patient.patient_id,\n",
    "                \"conditions\": conditions,\n",
    "                \"drugs\": drugs,\n",
    "            }\n",
    "        )\n",
    "    # exclude: patients with less than 2 visit\n",
    "    if len(samples) < 2:\n",
    "        return []\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a4eb0",
   "metadata": {},
   "source": [
    "**Extract Data**: Extracts the data from MIMIC-III tables using the Pyhealth MIMIC3Dataset. Returns a data object of the following: \n",
    "```\n",
    "{\n",
    "    \"single_visit_patients\": a list of visits for patients with only one visit,\n",
    "    \"multi_visit_patients\": a list of visits for patients with multile visits,\n",
    "    \"all_drugs\": a list of all the unique ATC codes in the data,\n",
    "    \"multi_visit_drugs\": a list of all the unique ATC codes in only the multi_visit_patients data,\n",
    "    \"all_conditions\": a list of all the unique ICD9 codes in the data,\n",
    "    \"multi_visit_conditions\": list of all unique ICD9 codes in only the multi_visit_patients data,\n",
    "    \"vocab\": a list of both ATC and ICD9 codes in data as well as the special codes: [PAD], [CLS], [MASK] \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d404e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    dataset = MIMIC3Dataset(\n",
    "        root=\"\",\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PRESCRIPTIONS\"],\n",
    "        code_mapping={\"NDC\": \"ATC\"},\n",
    "        # so the run time is shorter\n",
    "        dev=True,\n",
    "    )\n",
    "    \n",
    "    single_visit_patients = dataset.set_task(task_fn=single_visit_fn)\n",
    "    multi_visit_patients = dataset.set_task(task_fn=multi_visit_fn)\n",
    "    \n",
    "    all_drugs = set([drug for visit in single_visit_patients for drug in visit[\"drugs\"]])\n",
    "    multi_visit_drugs = set([drug for visit in multi_visit_patients for drug in visit[\"drugs\"]])\n",
    "    all_drugs = all_drugs.union(multi_visit_drugs)\n",
    "    \n",
    "    all_conditions = set([condition for visit in single_visit_patients for condition in visit[\"conditions\"]])\n",
    "    multi_visit_conditions = set([condition for visit in multi_visit_patients for condition in visit[\"conditions\"]])\n",
    "    all_conditions = all_conditions.union(multi_visit_conditions)\n",
    "    \n",
    "    vocab = list(all_drugs) + list(all_conditions) + [\"[PAD]\", \"[CLS]\", \"[MASK]\"]\n",
    "    \n",
    "    data = {\n",
    "        \"single_visit_patients\": list(single_visit_patients),\n",
    "        \"multi_visit_patients\": list(multi_visit_patients),\n",
    "        \"all_drugs\": list(all_drugs),\n",
    "        \"multi_visit_drugs\": list(multi_visit_drugs),\n",
    "        \"all_conditions\": list(all_conditions),\n",
    "        \"multi_visit_conditions\": list(multi_visit_conditions),\n",
    "        \"vocab\": vocab \n",
    "    }\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af86eb",
   "metadata": {},
   "source": [
    "**Split data**: Splits the ids of the patients with multiple visits into 3 lists for training, evaluating, and testing the model. Shang et al. divided the dataset using the following ration 0.6 : 0.2 : 0.2 ratio resectively and we did the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ae2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):    \n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    eval_ids = []\n",
    "    \n",
    "    multi_visit_patients = data[\"multi_visit_patients\"]\n",
    "    \n",
    "    all_ids = set([visit['patient_id'] for visit in multi_visit_patients])\n",
    "    all_ids = list(all_ids)\n",
    "    \n",
    "    random_numbers = [i for i in range(len(all_ids))]\n",
    "    random.shuffle(random_numbers)\n",
    "    \n",
    "    for i in range(int(len(all_ids)*2/3)):\n",
    "        train_ids.append(all_ids[random_numbers[i]])\n",
    "        \n",
    "    for i in range(int(len(all_ids)*2/3), int(len(all_ids)*5/6)):\n",
    "        eval_ids.append(all_ids[random_numbers[i]])\n",
    "        \n",
    "    for i in range(int(len(all_ids)*5/6), len(all_ids)):\n",
    "        test_ids.append(all_ids[random_numbers[i]])\n",
    "    \n",
    "    return train_ids, test_ids, eval_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6257f",
   "metadata": {},
   "source": [
    "**Padding and Truncating the Data**: when getting a sample from the dataset we set the length of the drug or condition codes list to a set value of 55.  If the list was under this length the token \\[PAD\\] would be added to make sure it got to the desired length.  If the list was over, it was shortened to be the appropriate length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee6c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate_data(data, max_len):\n",
    "    if len(data) < max_len:\n",
    "        while len(data) < max_len:\n",
    "            data.append('[PAD]')\n",
    "    else:\n",
    "        data = data[:max_len]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5070ff2",
   "metadata": {},
   "source": [
    "**Format Data for G-BERT**: the data in the G-BERT dataset was formatted in the following way:\n",
    "```\n",
    "data = { patient_id: [[[list of ICD9 codes for first visit], [list of ATC codes for first visit]], \n",
    "                      [[list of ICD9 codes for second visit], [list of ATC codes for second visit]],\n",
    "                      ...\n",
    "                      [[list of ICD9 codes for last visit], [list of ATC codes for last visit]]], ... }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c3c1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_GBERT(data):\n",
    "    data_dict = {}\n",
    "    for i in data:\n",
    "        if data_dict.__contains__(i[\"patient_id\"]):\n",
    "            data_dict[i[\"patient_id\"]].append([i[\"conditions\"], i[\"drugs\"]])\n",
    "        else:\n",
    "            data_dict[i[\"patient_id\"]] = [[i[\"conditions\"], i[\"drugs\"]]]\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ef43f",
   "metadata": {},
   "source": [
    "**EHR Dataset for G-BERT**: This is the dataset used for the Dataloaders when fine tuning the model.  Shang et al's code on github was used as a reference for this dataset. \n",
    "</br>\n",
    "reference:\n",
    "1. https://github.com/jshang123/G-Bert/tree/f5375265ecad5724c273712e13f3afa0e6a0f932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92dcb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EHRDatasetForGBERT(Dataset): \n",
    "    def __init__(self, visits, data, max_seq_len):\n",
    "\n",
    "        self.data = visits\n",
    "        self.multi_visit_conditions = data[\"multi_visit_conditions\"]\n",
    "        self.multi_visit_drugs = data[\"multi_visit_drugs\"]\n",
    "        self.vocab = data[\"vocab\"]\n",
    "        self.seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        subject_id = list(self.data.keys())[item]\n",
    "\n",
    "        def fill_to_max(l, seq):\n",
    "            while len(l) < seq:\n",
    "                l.append('[PAD]')\n",
    "            return l\n",
    "        \n",
    "        input_tokens = []  # (2*max_len*adm)\n",
    "        output_conditions_tokens = []  # (adm-1, l)\n",
    "        output_drug_tokens = []  # (adm-1, l)\n",
    "        \n",
    "        \n",
    "        for idx, adm in enumerate(self.data[subject_id]):\n",
    "            input_tokens.extend(\n",
    "                (['[CLS]'] + pad_or_truncate_data(list(adm[0]), self.seq_len - 1)))\n",
    "            input_tokens.extend(\n",
    "                (['[CLS]'] + pad_or_truncate_data(list(adm[1]), self.seq_len - 1)))\n",
    "\n",
    "            if idx != 0:\n",
    "                output_conditions_tokens.append(list(adm[0]))\n",
    "                output_drug_tokens.append(list(adm[1]))\n",
    "                \n",
    "        input_ids = []\n",
    "        for token in input_tokens:\n",
    "            input_ids.append(self.vocab.index(token))\n",
    "        \n",
    "        output_condition_labels = []\n",
    "        output_drug_labels = []\n",
    "        \n",
    "        condition_voc_size = len(self.multi_visit_conditions)\n",
    "        drug_voc_size = len(self.multi_visit_drugs)\n",
    "        for tokens in output_conditions_tokens:\n",
    "            tmp_labels = np.zeros(condition_voc_size)\n",
    "            tmp_labels[list(\n",
    "                map(lambda x: self.multi_visit_conditions.index(x), tokens))] = 1\n",
    "            output_condition_labels.append(tmp_labels)\n",
    "\n",
    "        for tokens in output_drug_tokens:\n",
    "            tmp_labels = np.zeros(drug_voc_size)\n",
    "            tmp_labels[list(\n",
    "                map(lambda x: self.multi_visit_drugs.index(x), tokens))] = 1\n",
    "            output_drug_labels.append(tmp_labels)\n",
    "        \n",
    "        cur_tensors = (torch.tensor(input_ids).view(-1, self.seq_len),\n",
    "                       torch.tensor(output_condition_labels, dtype=torch.float),\n",
    "                       torch.tensor(output_drug_labels, dtype=torch.float))\n",
    "        return cur_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d20567",
   "metadata": {},
   "source": [
    "**Get Data for G-BERT**: this code separates the data into groups based on the patient_id and initializes the training, testing, and validating datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d248c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_GBERT(data, train_ids, test_ids, eval_ids):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    eval_data = []\n",
    "    for i in data[\"multi_visit_patients\"]:\n",
    "        if i[\"patient_id\"] in train_ids:\n",
    "            train_data.append(i)\n",
    "        if i[\"patient_id\"] in test_ids:\n",
    "            test_data.append(i)\n",
    "        if i[\"patient_id\"] in eval_ids:\n",
    "            eval_data.append(i)\n",
    "    \n",
    "    train_data = EHRDatasetForGBERT(format_data_for_GBERT(train_data), data, 55)\n",
    "    test_data = EHRDatasetForGBERT(format_data_for_GBERT(test_data), data, 55)\n",
    "    eval_data = EHRDatasetForGBERT(format_data_for_GBERT(eval_data), data, 55)\n",
    "            \n",
    "    return train_data, test_data, eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd397d",
   "metadata": {},
   "source": [
    "**Format data for Pre-Training**: data was formatted for pretraining in the following way:\n",
    "```\n",
    "    data = [[[list of ICD9 codes for first visit], [list of ATC codes for first visit]], \n",
    "            [[list of ICD9 codes for next visit], [list of ATC codes for next visit]],\n",
    "            ...\n",
    "            [[list of ICD9 codes for last visit], [list of ATC codes for last visit]]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6817e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_pretraining(data):\n",
    "    data_list = []\n",
    "    for i in data:\n",
    "        visit = [i[\"conditions\"], i[\"drugs\"]]\n",
    "        data_list.append(visit)\n",
    "            \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30b5dd",
   "metadata": {},
   "source": [
    "**Random Word Masking**: in the pretraining step of G-BERT codes are masked at random with a 15% probability.  This code replaces those tokens with a \\[MASK\\] token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e94712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_word(tokens, vocab):\n",
    "    for i, _ in enumerate(tokens):\n",
    "        prob = random.random()\n",
    "        # mask token with 15% probability\n",
    "        if prob < 0.15:\n",
    "            tokens[i] = \"[MASK]\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e7b91",
   "metadata": {},
   "source": [
    "**EHR Dataset for Pretraining**: This is the dataset used for the Dataloaders when pretraining the model.  Shang et al's code on github was used as a reference for this dataset. \n",
    "</br>\n",
    "reference:\n",
    "1. https://github.com/jshang123/G-Bert/tree/f5375265ecad5724c273712e13f3afa0e6a0f932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703b0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EHRDatasetForPretraining(Dataset): \n",
    "    def __init__(self, visits, data, max_seq_len):\n",
    "\n",
    "        self.data = visits\n",
    "        self.all_conditions = data[\"all_conditions\"]\n",
    "        self.all_drugs = data[\"all_drugs\"]\n",
    "        self.seq_len = max_seq_len\n",
    "        self.vocab = data[\"vocab\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        cur_id = item\n",
    "        visit = copy.deepcopy(self.data[item])\n",
    "\n",
    "        y_conditions = np.zeros(len(self.all_conditions))\n",
    "        y_drugs = np.zeros(len(self.all_drugs))\n",
    "        for item in visit[0]:\n",
    "            y_conditions[self.all_conditions.index(item)] = 1\n",
    "        for item in visit[1]:\n",
    "            y_drugs[self.all_drugs.index(item)] = 1\n",
    "                 \n",
    "        visit[0] = random_word(visit[0], self.all_drugs)\n",
    "        visit[1] = random_word(visit[1], self.all_conditions)\n",
    "        \n",
    "        input_tokens = []  # (2*max_len)\n",
    "        input_tokens.extend(\n",
    "            ['[CLS]'] + pad_or_truncate_data(list(visit[0]), self.seq_len - 1))\n",
    "        input_tokens.extend(\n",
    "            ['[CLS]'] + pad_or_truncate_data(list(visit[1]), self.seq_len - 1))\n",
    "                 \n",
    "        input_ids = []\n",
    "        for token in input_tokens:\n",
    "            input_ids.append(self.vocab.index(token))\n",
    "    \n",
    "        cur_tensors = (torch.tensor(input_ids, dtype=torch.long).view(-1, self.seq_len),\n",
    "                       torch.tensor(y_conditions, dtype=torch.float),\n",
    "                       torch.tensor(y_drugs, dtype=torch.float))\n",
    "\n",
    "        return cur_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e790c8",
   "metadata": {},
   "source": [
    "**Get Data for Pre-Training**: this code separates the data into groups based on the patient_id and initializes the training and validating datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9be978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_pretraining(data, train_ids, eval_ids):\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    for i in data[\"multi_visit_patients\"]:\n",
    "        if i[\"patient_id\"] in train_ids:\n",
    "            train_data.append(i)\n",
    "        if i[\"patient_id\"] in eval_ids:\n",
    "            eval_data.append(i)\n",
    "    \n",
    "    train_data.extend(data[\"single_visit_patients\"])\n",
    "    \n",
    "    train_data = EHRDatasetForPretraining(format_data_for_pretraining(train_data), data, 55)\n",
    "    eval_data = EHRDatasetForPretraining(format_data_for_pretraining(eval_data), data, 55)\n",
    "            \n",
    "    return train_data, eval_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
