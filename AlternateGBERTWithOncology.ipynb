{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637a4129",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertModel' from 'ipynb.fs.full.Bert' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/5mnfst5x2f34jjgw4c2mr4680000gn/T/ipykernel_44071/2198234059.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtractData\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_for_pretraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_for_GBERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreTraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFineTuning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfine_tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS598_Final_Project/PreTraining.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"7feacb35\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m    \"source\": [\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BertModel' from 'ipynb.fs.full.Bert' (unknown location)"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.ExtractData import extract_data, split_data, get_data_for_pretraining, get_data_for_GBERT\n",
    "from ipynb.fs.full.PreTraining import pretrain\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from ipynb.fs.full.FineTuning import fine_tuning\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d7658",
   "metadata": {},
   "source": [
    "## GBERT with Ontology Embeddings\n",
    "In order to replicate the results of Shang et al. we are alternating the pretraining and fine tuning steps 15 times for 5 epochs each as they did in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13575fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for single_visit_fn: 100%|█| 1000/1000 [00:00<00:00, 32007.08\n",
      "Generating samples for multi_visit_fn: 100%|█| 1000/1000 [00:00<00:00, 27843.04i\n"
     ]
    }
   ],
   "source": [
    "data = extract_data()\n",
    "train_ids, test_ids, eval_ids = split_data(data)\n",
    "\n",
    "pretrain_data, pretrain_eval_data = get_data_for_pretraining(data, train_ids, eval_ids)\n",
    "pretrain_dataloader = DataLoader(pretrain_data, sampler=RandomSampler(pretrain_data), batch_size=4)\n",
    "pretrain_eval_dataloader = DataLoader(pretrain_eval_data, sampler=SequentialSampler(pretrain_eval_data), batch_size=4)\n",
    "\n",
    "train_data, eval_data, test_data = get_data_for_GBERT(data, train_ids, test_ids, eval_ids)\n",
    "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=1)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=SequentialSampler(eval_data), batch_size=1)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62356fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running Pre-training *****\n",
      "***** Running training *****\n",
      "train/loss: 0.6751239181951035  epoch:  1\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_dx2dx/ prauc :  0.17013174485178278  epoch:  1\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_rx2dx/ prauc :  0.17244882822794483  epoch:  1\n",
      "eval_dx2rx/ jaccard :  0.3016985445331728  epoch:  1\n",
      "eval_dx2rx/ f1 :  0.45998136431381215  epoch:  1\n",
      "eval_dx2rx/ prauc :  0.6376230896209196  epoch:  1\n",
      "eval_rx2rx/ jaccard :  0.2955657353353421  epoch:  1\n",
      "eval_rx2rx/ f1 :  0.4530976376590083  epoch:  1\n",
      "eval_rx2rx/ prauc :  0.6409476384390743  epoch:  1\n",
      "***** Running training *****\n",
      "train/loss: 0.5730645387671714  epoch:  2\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  2\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  2\n",
      "eval_dx2dx/ prauc :  0.1370985705038923  epoch:  2\n",
      "eval_rx2dx/ jaccard :  0.008159767234177398  epoch:  2\n",
      "eval_rx2dx/ f1 :  0.014696223316912971  epoch:  2\n",
      "eval_rx2dx/ prauc :  0.1550608249057221  epoch:  2\n",
      "eval_dx2rx/ jaccard :  0.2686023562476611  epoch:  2\n",
      "eval_dx2rx/ f1 :  0.42018038923707934  epoch:  2\n",
      "eval_dx2rx/ prauc :  0.6482183603413186  epoch:  2\n",
      "eval_rx2rx/ jaccard :  0.36114522422845075  epoch:  2\n",
      "eval_rx2rx/ f1 :  0.5198901960528114  epoch:  2\n",
      "eval_rx2rx/ prauc :  0.6407952176722818  epoch:  2\n",
      "***** Running training *****\n",
      "train/loss: 0.5557515666928402  epoch:  3\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  3\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  3\n",
      "eval_dx2dx/ prauc :  0.17757800053328052  epoch:  3\n",
      "eval_rx2dx/ jaccard :  0.008775241934204248  epoch:  3\n",
      "eval_rx2dx/ f1 :  0.016138390704397175  epoch:  3\n",
      "eval_rx2dx/ prauc :  0.1804111360072174  epoch:  3\n",
      "eval_dx2rx/ jaccard :  0.3628704991384946  epoch:  3\n",
      "eval_dx2rx/ f1 :  0.5251875815600076  epoch:  3\n",
      "eval_dx2rx/ prauc :  0.6492080742872313  epoch:  3\n",
      "eval_rx2rx/ jaccard :  0.37723807726141106  epoch:  3\n",
      "eval_rx2rx/ f1 :  0.5398575499713467  epoch:  3\n",
      "eval_rx2rx/ prauc :  0.6423706729943931  epoch:  3\n",
      "***** Running training *****\n",
      "train/loss: 0.5522990010505499  epoch:  4\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.019189987769842574  epoch:  4\n",
      "eval_dx2dx/ f1 :  0.035664626740733424  epoch:  4\n",
      "eval_dx2dx/ prauc :  0.16242083470871338  epoch:  4\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  4\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  4\n",
      "eval_rx2dx/ prauc :  0.17611069082348804  epoch:  4\n",
      "eval_dx2rx/ jaccard :  0.36719781433202203  epoch:  4\n",
      "eval_dx2rx/ f1 :  0.528665448646258  epoch:  4\n",
      "eval_dx2rx/ prauc :  0.6545252653449868  epoch:  4\n",
      "eval_rx2rx/ jaccard :  0.3726905228114285  epoch:  4\n",
      "eval_rx2rx/ f1 :  0.5340310924433379  epoch:  4\n",
      "eval_rx2rx/ prauc :  0.6504049806333522  epoch:  4\n",
      "***** Running training *****\n",
      "train/loss: 0.5498865280040475  epoch:  5\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.02155554995044693  epoch:  5\n",
      "eval_dx2dx/ f1 :  0.03957664134615133  epoch:  5\n",
      "eval_dx2dx/ prauc :  0.193402995935096  epoch:  5\n",
      "eval_rx2dx/ jaccard :  0.023686928352242755  epoch:  5\n",
      "eval_rx2dx/ f1 :  0.04282052390037871  epoch:  5\n",
      "eval_rx2dx/ prauc :  0.19039137553209914  epoch:  5\n",
      "eval_dx2rx/ jaccard :  0.3623921446468619  epoch:  5\n",
      "eval_dx2rx/ f1 :  0.5227163094285358  epoch:  5\n",
      "eval_dx2rx/ prauc :  0.6493469957594583  epoch:  5\n",
      "eval_rx2rx/ jaccard :  0.38617498605148187  epoch:  5\n",
      "eval_rx2rx/ f1 :  0.548215495086032  epoch:  5\n",
      "eval_rx2rx/ prauc :  0.6491198328154212  epoch:  5\n",
      "Pretrain 1 took  792.413341999054  seconds\n",
      "**********************************************************************************\n",
      "***** Running Fine Tuning *****\n",
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipynb.fs.full.ExtractData:247: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/loss: 0.3551404325460846  epoch:  1\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.38658701845948984  epoch:  1\n",
      "eval/ f1 :  0.5485959418824407  epoch:  1\n",
      "eval/ prauc :  0.6641406312742593  epoch:  1\n",
      "***** Running training *****\n",
      "train/loss: 0.31284626166928897  epoch:  2\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.36013825225931695  epoch:  2\n",
      "eval/ f1 :  0.519835650637712  epoch:  2\n",
      "eval/ prauc :  0.6493119299586991  epoch:  2\n",
      "***** Running training *****\n",
      "train/loss: 0.32382404313168744  epoch:  3\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.36156469937789976  epoch:  3\n",
      "eval/ f1 :  0.5239783634942653  epoch:  3\n",
      "eval/ prauc :  0.6554432511982251  epoch:  3\n",
      "***** Running training *****\n",
      "train/loss: 0.3148076112636111  epoch:  4\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3369860194394475  epoch:  4\n",
      "eval/ f1 :  0.4959058482475091  epoch:  4\n",
      "eval/ prauc :  0.658607294168624  epoch:  4\n",
      "***** Running training *****\n",
      "train/loss: 0.31240532852031966  epoch:  5\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3520369898917153  epoch:  5\n",
      "eval/ f1 :  0.5142033970502642  epoch:  5\n",
      "eval/ prauc :  0.6508141510590305  epoch:  5\n",
      "Fine Tuning 1 took  179.795001745224  seconds\n",
      "**********************************************************************************\n",
      "***** Running Pre-training *****\n",
      "***** Running training *****\n",
      "train/loss: 0.6010576137276583  epoch:  1\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_dx2dx/ prauc :  0.185319895441052  epoch:  1\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_rx2dx/ prauc :  0.18824474226028537  epoch:  1\n",
      "eval_dx2rx/ jaccard :  0.30591241831244487  epoch:  1\n",
      "eval_dx2rx/ f1 :  0.46467049206201383  epoch:  1\n",
      "eval_dx2rx/ prauc :  0.6622932227596533  epoch:  1\n",
      "eval_rx2rx/ jaccard :  0.37217233794762217  epoch:  1\n",
      "eval_rx2rx/ f1 :  0.5340530426336219  epoch:  1\n",
      "eval_rx2rx/ prauc :  0.6569541897330837  epoch:  1\n",
      "***** Running training *****\n",
      "train/loss: 0.5520484581936237  epoch:  2\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  2\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  2\n",
      "eval_dx2dx/ prauc :  0.17747438209260713  epoch:  2\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  2\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  2\n",
      "eval_rx2dx/ prauc :  0.19076461084064822  epoch:  2\n",
      "eval_dx2rx/ jaccard :  0.32640036235358233  epoch:  2\n",
      "eval_dx2rx/ f1 :  0.48726115993573144  epoch:  2\n",
      "eval_dx2rx/ prauc :  0.6572002851692611  epoch:  2\n",
      "eval_rx2rx/ jaccard :  0.39332674306443244  epoch:  2\n",
      "eval_rx2rx/ f1 :  0.5559414740565539  epoch:  2\n",
      "eval_rx2rx/ prauc :  0.6503254920521769  epoch:  2\n",
      "***** Running training *****\n",
      "train/loss: 0.5498639166355133  epoch:  3\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  3\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  3\n",
      "eval_dx2dx/ prauc :  0.18529304643485384  epoch:  3\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  3\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  3\n",
      "eval_rx2dx/ prauc :  0.18206014676795684  epoch:  3\n",
      "eval_dx2rx/ jaccard :  0.3705186994973007  epoch:  3\n",
      "eval_dx2rx/ f1 :  0.5332014379167194  epoch:  3\n",
      "eval_dx2rx/ prauc :  0.6537884363528893  epoch:  3\n",
      "eval_rx2rx/ jaccard :  0.3710660469697852  epoch:  3\n",
      "eval_rx2rx/ f1 :  0.5332225755567803  epoch:  3\n",
      "eval_rx2rx/ prauc :  0.6584162630596327  epoch:  3\n",
      "***** Running training *****\n",
      "train/loss: 0.5407213132048763  epoch:  4\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0009074410163339383  epoch:  4\n",
      "eval_dx2dx/ f1 :  0.001724137931034483  epoch:  4\n",
      "eval_dx2dx/ prauc :  0.1866876288603016  epoch:  4\n",
      "eval_rx2dx/ jaccard :  0.007785388119940271  epoch:  4\n",
      "eval_rx2dx/ f1 :  0.014424547975566585  epoch:  4\n",
      "eval_rx2dx/ prauc :  0.18483617493289292  epoch:  4\n",
      "eval_dx2rx/ jaccard :  0.3622194974543042  epoch:  4\n",
      "eval_dx2rx/ f1 :  0.524130079529283  epoch:  4\n",
      "eval_dx2rx/ prauc :  0.6558065592204984  epoch:  4\n",
      "eval_rx2rx/ jaccard :  0.38718747569426093  epoch:  4\n",
      "eval_rx2rx/ f1 :  0.5489259179476796  epoch:  4\n",
      "eval_rx2rx/ prauc :  0.6484714161969641  epoch:  4\n",
      "***** Running training *****\n",
      "train/loss: 0.5303897319838058  epoch:  5\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0422731943749879  epoch:  5\n",
      "eval_dx2dx/ f1 :  0.07592037424160836  epoch:  5\n",
      "eval_dx2dx/ prauc :  0.191535984203886  epoch:  5\n",
      "eval_rx2dx/ jaccard :  0.003682507485752922  epoch:  5\n",
      "eval_rx2dx/ f1 :  0.006867079280872384  epoch:  5\n",
      "eval_rx2dx/ prauc :  0.17423422503423563  epoch:  5\n",
      "eval_dx2rx/ jaccard :  0.365936737334514  epoch:  5\n",
      "eval_dx2rx/ f1 :  0.5298458557364245  epoch:  5\n",
      "eval_dx2rx/ prauc :  0.663184376208951  epoch:  5\n",
      "eval_rx2rx/ jaccard :  0.32193041576656256  epoch:  5\n",
      "eval_rx2rx/ f1 :  0.4758132613682348  epoch:  5\n",
      "eval_rx2rx/ prauc :  0.6652947948662951  epoch:  5\n",
      "Pretrain  2  took  792.1458899974823  seconds\n",
      "**********************************************************************************\n",
      "***** Running Fine Tuning *****\n",
      "***** Running training *****\n",
      "train/loss: 0.35472277348691766  epoch:  1\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3736203891351856  epoch:  1\n",
      "eval/ f1 :  0.5345837759397891  epoch:  1\n",
      "eval/ prauc :  0.6588017748827313  epoch:  1\n",
      "***** Running training *****\n",
      "train/loss: 0.3157264600423249  epoch:  2\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3537441417342038  epoch:  2\n",
      "eval/ f1 :  0.5143200794866779  epoch:  2\n",
      "eval/ prauc :  0.6540932585989486  epoch:  2\n",
      "***** Running training *****\n",
      "train/loss: 0.3194875666363673  epoch:  3\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3141909145467728  epoch:  3\n",
      "eval/ f1 :  0.4707031967705136  epoch:  3\n",
      "eval/ prauc :  0.6435571273556792  epoch:  3\n",
      "***** Running training *****\n",
      "train/loss: 0.31208109635521064  epoch:  4\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.35681440100207923  epoch:  4\n",
      "eval/ f1 :  0.5161179066050784  epoch:  4\n",
      "eval/ prauc :  0.6677656156611991  epoch:  4\n",
      "***** Running training *****\n",
      "train/loss: 0.3155629457059232  epoch:  5\n",
      "***** Running eval *****\n",
      "eval/ jaccard :  0.3360646630897442  epoch:  5\n",
      "eval/ f1 :  0.49561415062423975  epoch:  5\n",
      "eval/ prauc :  0.669204392306343  epoch:  5\n",
      "Fine Tuning  2  took  183.47368097305298  seconds\n",
      "**********************************************************************************\n",
      "***** Running Pre-training *****\n",
      "***** Running training *****\n",
      "train/loss: 0.6094470298567484  epoch:  1\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_dx2dx/ prauc :  0.17473866426792675  epoch:  1\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  1\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  1\n",
      "eval_rx2dx/ prauc :  0.17255020890830425  epoch:  1\n",
      "eval_dx2rx/ jaccard :  0.31889718303944886  epoch:  1\n",
      "eval_dx2rx/ f1 :  0.47895445793524255  epoch:  1\n",
      "eval_dx2rx/ prauc :  0.6500209577348146  epoch:  1\n",
      "eval_rx2rx/ jaccard :  0.38551229126194736  epoch:  1\n",
      "eval_rx2rx/ f1 :  0.5488812690819164  epoch:  1\n",
      "eval_rx2rx/ prauc :  0.6464393966485141  epoch:  1\n",
      "***** Running training *****\n",
      "train/loss: 0.5563573443612387  epoch:  2\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  2\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  2\n",
      "eval_dx2dx/ prauc :  0.18387996799448875  epoch:  2\n",
      "eval_rx2dx/ jaccard :  0.00557166165151646  epoch:  2\n",
      "eval_rx2dx/ f1 :  0.0103963056065952  epoch:  2\n",
      "eval_rx2dx/ prauc :  0.09335146959962365  epoch:  2\n",
      "eval_dx2rx/ jaccard :  0.33777058926110254  epoch:  2\n",
      "eval_dx2rx/ f1 :  0.49941752561536645  epoch:  2\n",
      "eval_dx2rx/ prauc :  0.6528563660256513  epoch:  2\n",
      "eval_rx2rx/ jaccard :  0.1028549534891674  epoch:  2\n",
      "eval_rx2rx/ f1 :  0.16003803414394782  epoch:  2\n",
      "eval_rx2rx/ prauc :  0.5779765348495589  epoch:  2\n",
      "***** Running training *****\n",
      "train/loss: 0.5511742953644242  epoch:  3\n",
      "***** Running eval *****\n",
      "eval_dx2dx/ jaccard :  0.0  epoch:  3\n",
      "eval_dx2dx/ f1 :  0.0  epoch:  3\n",
      "eval_dx2dx/ prauc :  0.19725038755759178  epoch:  3\n",
      "eval_rx2dx/ jaccard :  0.0  epoch:  3\n",
      "eval_rx2dx/ f1 :  0.0  epoch:  3\n",
      "eval_rx2dx/ prauc :  0.19472228004840017  epoch:  3\n",
      "eval_dx2rx/ jaccard :  0.368837495587865  epoch:  3\n",
      "eval_dx2rx/ f1 :  0.533109984816001  epoch:  3\n",
      "eval_dx2rx/ prauc :  0.6589524105732439  epoch:  3\n",
      "eval_rx2rx/ jaccard :  0.37761361654457104  epoch:  3\n",
      "eval_rx2rx/ f1 :  0.5408691969229273  epoch:  3\n",
      "eval_rx2rx/ prauc :  0.6601102164069408  epoch:  3\n",
      "***** Running training *****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/5mnfst5x2f34jjgw4c2mr4680000gn/T/ipykernel_43196/956332556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**********************************************************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_eval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gbert-with-ontology.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musePretrainedModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museGraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pretrain \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" took \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**********************************************************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL4H_Final_Proj/PreTraining.ipynb\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(data, train_dataloader, eval_dataloader, outputFileName, usePretrainedModel, useGraph)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"                              else \\\"cpu\\\")\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;34m\"    if usePretrainedModel:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;34m\"        model = BERT_Pretrain.from_pretrained(data, useGraph, outputFileName)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m\"    else:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pretrain(data, pretrain_dataloader, pretrain_eval_dataloader, \"gbert-with-ontology.bin\", usePretrainedModel=False, useGraph=True)\n",
    "print(\"Pretrain 1 took \", (time.time() - start_time), \" seconds\")\n",
    "print(\"**********************************************************************************\")\n",
    "start_time = time.time()\n",
    "fine_tuning(data, train_dataloader, eval_dataloader, test_dataloader, \"gbert-with-ontology.bin\", useGraph=True)\n",
    "print(\"Fine Tuning 1 took \", (time.time() - start_time), \" seconds\")\n",
    "\n",
    "for i in range(14):\n",
    "    print(\"**********************************************************************************\")\n",
    "    start_time = time.time()\n",
    "    pretrain(data, pretrain_dataloader, pretrain_eval_dataloader, \"gbert-with-ontology.bin\", usePretrainedModel=True, useGraph=True)\n",
    "    print(\"Pretrain \", i+2, \" took \", (time.time() - start_time), \" seconds\")\n",
    "    print(\"**********************************************************************************\")\n",
    "    start_time = time.time()\n",
    "    fine_tuning(data, train_dataloader, eval_dataloader, test_dataloader, \"gbert-with-ontology.bin\", useGraph=True)\n",
    "    print(\"Fine Tuning \", i+2, \" took \", (time.time() - start_time), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095221c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
