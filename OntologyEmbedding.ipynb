{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "464f6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.ExtractData as extractData\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.utils import add_self_loops, softmax, scatter_\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e4181",
   "metadata": {},
   "source": [
    "## Ontology Embedding\n",
    "This file contains the methods for creating the ontology embeddings for G-BERT.  Most of the code is taken from the G-BERT Github Repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb0594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glorot(tensor):\n",
    "    stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e68260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46401acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATConv(nn.Module):\n",
    "    r\"\"\"The graph attentional operator from the `\"Graph Attention Networks\"\n",
    "    <https://arxiv.org/abs/1710.10903>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{j} +\n",
    "        \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j},\n",
    "\n",
    "    where the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
    "\n",
    "    .. math::\n",
    "        \\alpha_{i,j} =\n",
    "        \\frac{\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_j]\n",
    "        \\right)\\right)}\n",
    "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_k]\n",
    "        \\right)\\right)}.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        heads (int, optional): Number of multi-head-attentions. (default:\n",
    "            :obj:`1`)\n",
    "        concat (bool, optional): If set to :obj:`False`, the multi-head\n",
    "        attentions are averaged instead of concatenated. (default: :obj:`True`)\n",
    "        negative_slope (float, optional): LeakyReLU angle of the negative\n",
    "            slope. (default: :obj:`0.2`)\n",
    "        dropout (float, optional): Dropout probability of the normalized\n",
    "            attention coefficients which exposes each node to a stochastically\n",
    "            sampled neighborhood during training. (default: :obj:`0`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 heads=1,\n",
    "                 negative_slope=0.2,\n",
    "                 dropout=0,\n",
    "                 bias=True):\n",
    "        super(GATConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_channels, heads * out_channels))\n",
    "        self.att = nn.Parameter(torch.Tensor(1, heads, 2 * out_channels))\n",
    "        self.bias = nn.Parameter(torch.Tensor(heads * out_channels))\n",
    "        \n",
    "        self.message_args = inspect.getargspec(self.message)[0][1:]\n",
    "        self.update_args = inspect.getargspec(self.update)[0][2:]\n",
    "\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def propagate(self, aggr, edge_index, **kwargs):\n",
    "        r\"\"\"The initial call to start propagating messages.\n",
    "        Takes in an aggregation scheme (:obj:`\"add\"`, :obj:`\"mean\"` or\n",
    "        :obj:`\"max\"`), the edge indices, and all additional data which is\n",
    "        needed to construct messages and to update node embeddings.\"\"\"\n",
    "\n",
    "        assert aggr in ['add', 'mean', 'max']\n",
    "        kwargs['edge_index'] = edge_index\n",
    "\n",
    "        size = None\n",
    "        message_args = []\n",
    "        for arg in self.message_args:\n",
    "            if arg[-2:] == '_i':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[0]])\n",
    "            elif arg[-2:] == '_j':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[1]])\n",
    "            else:\n",
    "                message_args.append(kwargs[arg])\n",
    "\n",
    "        update_args = [kwargs[arg] for arg in self.update_args]\n",
    "\n",
    "        out = self.message(*message_args)\n",
    "        out = scatter_(aggr, out, edge_index[0], dim_size=size)\n",
    "        out = self.update(out, *update_args)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        glorot(self.att)\n",
    "        zeros(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = torch.mm(x, self.weight).view(-1, self.heads, self.out_channels)\n",
    "        return self.propagate('add', edge_index, x=x, num_nodes=x.size(0))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, num_nodes):\n",
    "        # Compute attention coefficients.\n",
    "        alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = softmax(alpha, edge_index[0], num_nodes)\n",
    "\n",
    "        alpha = F.dropout(alpha, p=self.dropout)\n",
    "\n",
    "        return x_j * alpha.view(-1, self.heads, 1)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        aggr_out = aggr_out.view(-1, self.heads * self.out_channels)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ef8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_level2():\n",
    "    level2 = ['001-009', '010-018', '020-027', '030-041', '042', '045-049', '050-059', '060-066', '070-079', '080-088', '090-099', '100-104', '110-118', '120-129', '130-136', '137-139', '140-149', '150-159', '160-165', '170-176', '176', '179-189', '190-199', '200-208', '209', '210-229', '230-234', '235-238', '239', '240-246', '249-259', '260-269', '270-279', '280-289', '290-294', '295-299', '300-316', '317-319', '320-327', '330-337', '338', '339', '340-349', '350-359', '360-379', '380-389', '390-392', '393-398', '401-405', '410-414', '415-417', '420-429', '430-438', '440-449', '451-459', '460-466', '470-478', '480-488', '490-496', '500-508', '510-519', '520-529', '530-539', '540-543', '550-553', '555-558', '560-569', '570-579', '580-589', '590-599', '600-608', '610-611', '614-616', '617-629', '630-639', '640-649', '650-659', '660-669', '670-677', '678-679', '680-686', '690-698', '700-709', '710-719', '720-724', '725-729', '730-739', '740-759', '760-763', '764-779', '780-789', '790-796', '797-799', '800-804', '805-809', '810-819', '820-829', '830-839', '840-848', '850-854', '860-869', '870-879', '880-887', '890-897', '900-904', '905-909', '910-919', '920-924', '925-929', '930-939', '940-949', '950-957', '958-959', '960-979', '980-989', '990-995', '996-999', 'V01-V91', 'V01-V09', 'V10-V19', 'V20-V29', 'V30-V39', 'V40-V49', 'V50-V59', 'V60-V69', 'V70-V82', 'V83-V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'E000-E899', 'E000', 'E001-E030', 'E800-E807', 'E810-E819', 'E820-E825', 'E826-E829', 'E830-E838', 'E840-E845', 'E846-E849', 'E850-E858', 'E860-E869', 'E870-E876', 'E878-E879', 'E880-E888', 'E890-E899', 'E900-E909', 'E910-E915', 'E916-E928', 'E929', 'E930-E949', 'E950-E959', 'E960-E969', 'E970-E978', 'E980-E989', 'E990-E999']\n",
    "\n",
    "    level2_expand = {}\n",
    "    for i in level2:\n",
    "        tokens = i.split('-')\n",
    "        if i[0] == 'V':\n",
    "            if len(tokens) == 1:\n",
    "                level2_expand[i] = i\n",
    "            else:\n",
    "                for j in range(int(tokens[0][1:]), int(tokens[1][1:]) + 1):\n",
    "                    level2_expand[\"V%02d\" % j] = i\n",
    "        elif i[0] == 'E':\n",
    "            if len(tokens) == 1:\n",
    "                level2_expand[i] = i\n",
    "            else:\n",
    "                for j in range(int(tokens[0][1:]), int(tokens[1][1:]) + 1):\n",
    "                    level2_expand[\"E%03d\" % j] = i\n",
    "        else:\n",
    "            if len(tokens) == 1:\n",
    "                level2_expand[i] = i\n",
    "            else:\n",
    "                for j in range(int(tokens[0]), int(tokens[1]) + 1):\n",
    "                    level2_expand[\"%03d\" % j] = i\n",
    "    \n",
    "    return level2_expand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f840b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_icd9_tree(codes):\n",
    "    \n",
    "    icd9_tree = []\n",
    "    vocabulary = []\n",
    "\n",
    "    root_node = 'icd9_root'\n",
    "    level3_dict = expand_level2()\n",
    "    for code in codes:\n",
    "        level1 = code\n",
    "        level2 = level1[:4] if level1[0] == 'E' else level1[:3]\n",
    "        level3 = level3_dict[level2]\n",
    "        level4 = root_node\n",
    "\n",
    "        sample = [level1, level2, level3, level4]\n",
    "\n",
    "        for i in sample:\n",
    "            vocabulary.append(i)\n",
    "        icd9_tree.append(sample)\n",
    "\n",
    "    return icd9_tree, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69aa4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_atc_tree(codes):\n",
    "    atc_tree = []\n",
    "    vocabulary = set()\n",
    "    \n",
    "    root_node = 'atc_root'\n",
    "    for code in codes:\n",
    "        sample = [code]\n",
    "        sample.append(code[:4])\n",
    "        sample.append(code[:3])\n",
    "        sample.append(code[:1])\n",
    "        sample.append(root_node)\n",
    "\n",
    "        atc_tree.append(sample)\n",
    "        for i in sample:\n",
    "            vocabulary.add(i)\n",
    "        \n",
    "\n",
    "    return atc_tree, list(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a03550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage_one_edges(tree, vocabulary):\n",
    "    edge_idx = set()\n",
    "    for sample in tree:\n",
    "        sample_idx = list(map(lambda word: vocabulary.index(word), sample))\n",
    "\n",
    "        for i in range(len(sample_idx) - 1):\n",
    "            # only direct children -> ancestor\n",
    "            edge_idx.add((sample_idx[i+1], sample_idx[i]))\n",
    "\n",
    "    edge_idx = list(edge_idx)\n",
    "    row = list(map(lambda x: x[0], edge_idx))\n",
    "    col = list(map(lambda x: x[1], edge_idx))\n",
    "    return [row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44dd0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage_two_edges(tree, vocabulary):\n",
    "    edge_idx = []\n",
    "    for sample in tree:\n",
    "        sample_idx = list(map(lambda word: vocabulary.index(word), sample))\n",
    "        # only ancestors -> leaf node\n",
    "        edge_idx.extend([(sample_idx[0], sample_idx[i])\n",
    "                         for i in range(1, len(sample_idx))])\n",
    "\n",
    "    edge_idx = list(set(edge_idx))\n",
    "    row = list(map(lambda x: x[0], edge_idx))\n",
    "    col = list(map(lambda x: x[1], edge_idx))\n",
    "    return [row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826d0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyEmbedding(nn.Module):\n",
    "    def __init__(self, all_codes, build_tree_func):\n",
    "        super(OntologyEmbedding, self).__init__()\n",
    "\n",
    "        # initial tree edges\n",
    "        tree, vocabulary = build_tree_func(all_codes)\n",
    "        stage_one_edges = build_stage_one_edges(tree, vocabulary)\n",
    "        stage_two_edges = build_stage_two_edges(tree, vocabulary)\n",
    "\n",
    "        self.edges1 = torch.tensor(stage_one_edges)\n",
    "        self.edges2 = torch.tensor(stage_two_edges)\n",
    "        self.graph_vocab = vocabulary\n",
    "\n",
    "        # construct model\n",
    "        self.g = GATConv(in_channels=300, out_channels=75, heads=4)\n",
    "\n",
    "        # tree embedding\n",
    "        num_nodes = len(vocabulary)\n",
    "        self.embedding = nn.Parameter(torch.Tensor(num_nodes, 300))\n",
    "\n",
    "        # idx mapping: FROM leaf node in graphvoc TO voc\n",
    "        self.idx_mapping = [self.graph_vocab.index(code) for code in all_codes]\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self):\n",
    "        emb = self.embedding\n",
    "\n",
    "        emb = self.g(self.g(emb, self.edges1.to(emb.device)), self.edges2.to(emb.device))\n",
    "\n",
    "        return emb[self.idx_mapping]\n",
    "\n",
    "    def init_params(self):\n",
    "        glorot(self.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69ed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuseEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from ontology, patient info and type embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, all_conditions, all_drugs, vocab_size):\n",
    "        super(FuseEmbeddings, self).__init__()\n",
    "        self.special_embedding = nn.Parameter(torch.Tensor(3, 300))\n",
    "        self.drug_embedding = OntologyEmbedding(all_drugs, build_atc_tree)\n",
    "        self.conditions_embedding = OntologyEmbedding(all_conditions, build_icd9_tree)\n",
    "        \n",
    "        self.init_params()\n",
    "        self.type_embedding = nn.Embedding(2, 300)\n",
    "\n",
    "    def forward(self, input_ids, input_types=None):\n",
    "        # return self.ontology_embedding(input_ids)\n",
    "        concat_embeddings = torch.cat([self.special_embedding, self.drug_embedding(), self.conditions_embedding()], dim=0)\n",
    "        ontology_embedding = concat_embeddings[input_ids] + self.type_embedding(input_types)\n",
    "        return ontology_embedding\n",
    "    \n",
    "    def init_params(self):\n",
    "        glorot(self.special_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
